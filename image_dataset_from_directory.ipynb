{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlu_tools.utils as mlutils\n",
    "from utils.consts import DATASET_DIR\n",
    "from mlu_tools.plotting import grid_plot\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1tVXlXFr4xamxut9bV7GFUQlgm8XiiRQf&export=download\n",
      "To: /home/vikas/Lab/Decoding NNs/datasets/dummy_dataset.zip\n",
      "100%|██████████| 17.5M/17.5M [00:04<00:00, 4.15MB/s]\n"
     ]
    }
   ],
   "source": [
    "# downloading dummy_dataset\n",
    "dataset_url = \"https://drive.google.com/file/d/1tVXlXFr4xamxut9bV7GFUQlgm8XiiRQf/view?usp=drive_link\"\n",
    "save_dataset_as = f\"{DATASET_DIR}/dummy_dataset.zip\"\n",
    "mlutils.download(dataset_url, save_dataset_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip dataset\n",
    "!unzip \"{save_dataset_as}\" -d \"{DATASET_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "dummy_dataset_dir = f\"{DATASET_DIR}/dummy_dataset\"\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dummy_dataset_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "└── dummy_dataset\n",
      "    ├── 0 - 12\n",
      "    ├── 1 - 12\n",
      "    └── 2 - 12\n"
     ]
    }
   ],
   "source": [
    "mlutils.tree(dummy_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 19:21:15.198327: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25165824 exceeds 10% of free system memory.\n",
      "2024-12-21 19:21:15.294341: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25165824 exceeds 10% of free system memory.\n",
      "2024-12-21 19:21:15.307007: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(10):\n",
    "    print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.keras.preprocessing.image_dataset_from_directory**\n",
    "\n",
    "- This function creates a pool of all the images from all the subdirectories (subdirectories 0, 1 and 2 in our case).\n",
    "- Each subdirectory is having 12 images in our case so the pool will have 12+12+12=36 images.\n",
    "- By default the batch size is 32 for image_dataset_from_directory function.\n",
    "- If we call train_ds.take(1) it will fetch 32 images our of 36 total images.\n",
    "- If we call train_ds.take(2) it will fetch two batches, first one of 32 images and second one of 4 images totaling 36 images.\n",
    "- If we call train_ds.take(n) where n is a number greater than 2, we will still have two batches as described above since we have 36 images in total.\n",
    "- If we set batch size of 12 then we will can fetch 3 batches at max each having 12 images.\n",
    "- If we had 40 images in total then the total number of batches that could be fetched were 4 where first 3 batches were having 12 images each and the last one was having 4 images totaling 40 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
