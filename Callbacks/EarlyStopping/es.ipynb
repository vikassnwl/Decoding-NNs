{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 21:05:39.961369: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-26 21:05:48.795711: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import mlu_tools.utils as mlutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_full, y_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = X_full[:-10000], X_full[-10000:]\n",
    "y_train, y_val = y_full[:-10000], y_full[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8001 - loss: 0.7698 - val_accuracy: 0.9169 - val_loss: 0.3062\n",
      "Epoch 2/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.3274 - val_accuracy: 0.9233 - val_loss: 0.2777\n",
      "Epoch 3/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2990 - val_accuracy: 0.9269 - val_loss: 0.2674\n",
      "Epoch 4/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2862 - val_accuracy: 0.9291 - val_loss: 0.2621\n",
      "Epoch 5/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2783 - val_accuracy: 0.9299 - val_loss: 0.2589\n",
      "Epoch 6/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2727 - val_accuracy: 0.9308 - val_loss: 0.2569\n",
      "Epoch 7/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2685 - val_accuracy: 0.9316 - val_loss: 0.2556\n",
      "Epoch 8/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2651 - val_accuracy: 0.9315 - val_loss: 0.2548\n",
      "Epoch 9/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.2622 - val_accuracy: 0.9314 - val_loss: 0.2543\n",
      "Epoch 10/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.2598 - val_accuracy: 0.9317 - val_loss: 0.2540\n",
      "Epoch 11/20\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.2577 - val_accuracy: 0.9316 - val_loss: 0.2538\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f15d4253670>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlutils.set_global_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28)),\n",
    "    tf.keras.layers.Rescaling(1.0/255),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",   # The metric to monitor for early stopping (validation accuracy in this case)\n",
    "    verbose=1,                 # If set to 1, will display messages when early stopping is triggered\n",
    "    patience=4,                # Number of epochs with no improvement before stopping\n",
    "    min_delta=0.0001,          # Minimum change to qualify as an improvement (to prevent stopping for minor fluctuations)\n",
    "    restore_best_weights=True # Restore the model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
